{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Machine learning para Megaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1 Contenido](#content)\n",
    "* [2 Introducción](#intro)\n",
    "* [3 Inicialización](#inic)\n",
    "    * [3.1 Cargar Librerias](#library)\n",
    "    * [3.2 Cargar Datos](#datos)\n",
    "* [4 Exploración de los datos](#exp)       \n",
    "* [5 Segmentación de los datos](#segmentacion) \n",
    "* [6 Mejoramiento de los modelos](#mejoramiento)\n",
    "    * [6.1 Árbol de desición](#arbol)\n",
    "    * [6.2 Bosque aleatorio](#bosque)\n",
    "    * [6.3 Regresión logística](#regresion)    \n",
    "* [7 Calidad y elección del modelo](#model)\n",
    "* [8 Conclusión general](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el presente proyecto desarrollaremos un modelo que analice el comportamiento de los clientes de la empresa Megaline y recomiende uno de los nuevos planes Smart o Ultra de la empresa. Comenzaremos segmentando los datos, analizaremos distintos tipos de modelos para posteriormente elegir el que mejor resultado tenga y ponerlo a prueba con la base de datos otorgada por Megaline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cargar librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a cargar las librerías que se utilizaran en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploración de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, le daremos un vistazo a la base de datos entregada por Megaline, como ya se realizó un análisis de las mismas bases de datos en un proyecto anterior se procederá con una exploración rápida para ver que todo se encuentre en orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "plan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls 3214\n",
      "minutes 3214\n",
      "messages 3214\n",
      "mb_used 3214\n",
      "is_ultra 3214\n"
     ]
    }
   ],
   "source": [
    "for column in plan:\n",
    "    print(f'{column} {len(plan[plan[column]>=0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plan['is_ultra'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar no hay datos ausentes en el dataframe, no hay datos extraños como valores negativos en las columnas y la columna \"is_ultra\" solo tiene dos tipos distintos de valores, 0 y 1, como debería ser al ser una columna con datos binarios. Con respecto al dataframe en sí mismo podemos apreciar que la columna \"is_ultra\" será nuestra columna \"objetivo\" que intentara predecir nuestro modelo y el resto de las columnas serán las \"características\" que ayudaran al modelo a realizar las predicciones. Es de importancia resaltar que nuestra columna objetivo es de tipo categórica ya que consiste en un valor binario que indica si el plan es de un tipo u otro, por lo que en base a esta característica serán los algoritmos de aprendizaje que se utilizarán más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Segmentación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos dividiendo el dataframe en dos, uno con las columnas \"características\" y otro con la columna \"objetivo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = plan.drop('is_ultra', axis=1)\n",
    "target = plan['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procederemos a realizar la segmentación de los datos en tres conjuntos, uno de entrenamiento, uno de validación y uno de prueba. Para llevarlo a cabo utilizaremos la función \"train_test_split\" la cual separa nuestro dataframe en dos, como necesitamos tres conjuntos realizaremos este proceso dos veces para conseguir los conjuntos anteriormente mencionados en una proporción de 3:1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train1, features_valid, target_train1, target_valid = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_train1, target_train1, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train 0.5998755444928439\n",
      "features_train 0.2000622277535781\n",
      "features_train 0.2000622277535781\n"
     ]
    }
   ],
   "source": [
    "print(f'features_train {len(features_train)/len(features)}')\n",
    "print(f'features_train {len(features_valid)/len(features)}')\n",
    "print(f'features_train {len(features_test)/len(features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que hemos conseguido los tres conjuntos de dataframes en las proporciones requeridas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mejoramiento de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, evaluaremos independientemente distintos tipos de algoritmos de aprendizaje ajustando sus hiperpárametros para mejorar el modelo y obtener la mayor exactitud posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7480559875583204\n",
      "max_depth = 2 : 0.7838258164852255\n",
      "max_depth = 3 : 0.7869362363919129\n",
      "max_depth = 4 : 0.7869362363919129\n",
      "max_depth = 5 : 0.7884914463452566\n",
      "max_depth = 6 : 0.7791601866251944\n",
      "max_depth = 7 : 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,8):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'max_depth = {depth} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos analizando distintos valores de \"profundidad máxima\" para el árbol de decisión, con las pruebas realizadas el valor más exacto para las predicciones realizadas es con una profundidad de 3 y 4, por lo que nos decantaremos por el primer valor para reducir tiempos de carga asociados a mayor profundidad en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf = 1 : 0.7884914463452566\n",
      "min_samples_leaf = 2 : 0.7853810264385692\n",
      "min_samples_leaf = 3 : 0.7931570762052877\n",
      "min_samples_leaf = 4 : 0.7916018662519441\n",
      "min_samples_leaf = 5 : 0.7869362363919129\n",
      "min_samples_leaf = 6 : 0.7869362363919129\n",
      "min_samples_leaf = 7 : 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "for leaf in range(1,8):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=5, min_samples_leaf=leaf)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'min_samples_leaf = {leaf} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el valor de max_depth ya seleccionado, continuamos probando valores para min_samples_leaf, en este caso el mejor resultado se obtiene con un valor de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy : 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy', random_state=12345, max_depth=5, min_samples_leaf=3)\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_valid) \n",
    "result = accuracy_score(target_valid, predictions)\n",
    "print(f'criterion = entropy : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos cambiando el criterion del modelo, el valor por defecto con el que hemos realizado las pruebas anteriores es \"gini\" por lo que procedimos a cambiarlo por \"entropy\" obteniendo una exactitud mayor con los hiperparámetros antes escogidos por lo que procederemos a quedarnos con este último criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " min_samples_split = 2 : 0.7962674961119751\n",
      " min_samples_split = 3 : 0.7962674961119751\n",
      " min_samples_split = 4 : 0.7962674961119751\n",
      " min_samples_split = 5 : 0.7962674961119751\n",
      " min_samples_split = 6 : 0.7962674961119751\n",
      " min_samples_split = 7 : 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "for split in range(2,8):\n",
    "    model = DecisionTreeClassifier(criterion='entropy', random_state=12345, max_depth=5, min_samples_leaf=3, min_samples_split=split)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f' min_samples_split = {split} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente modificaremos los valores de \"min_samples_split\", en este caso observamos que modificar este hiperparámetro no afecta la exactitud de nuestro modelo por lo que nos quedaremos con el valor por defecto de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos realizado pruebas en distintos hiperparámetros de nuestro algoritmo de aprendizaje \"árbol de decisión\" quedándonos finalmente con un \"max_depth\" de 5, \"min_samples_leaf\" de 3, \"criterion\" de \"entropy\" y el resto con sus valores por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 : 0.7869362363919129\n",
      "n_estimators = 20 : 0.7791601866251944\n",
      "n_estimators = 30 : 0.7853810264385692\n",
      "n_estimators = 40 : 0.7900466562986003\n",
      "n_estimators = 50 : 0.7884914463452566\n",
      "n_estimators = 60 : 0.7853810264385692\n",
      "n_estimators = 70 : 0.7838258164852255\n",
      "n_estimators = 80 : 0.7869362363919129\n",
      "n_estimators = 90 : 0.7900466562986003\n",
      "n_estimators = 100 : 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "for est in range(10, 101, 10):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'n_estimators = {est} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del algoritmo \"bosque aleatorio\" comenzamos probando distintos valores para \"n_estimators\", en este caso concluimos que la mayor exactitud la obtenemos con los valores de 40 y 90, utilizaremos el primero para reducir tiempos de carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy : 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=40, criterion='entropy')\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_valid) \n",
    "result = accuracy_score(target_valid, predictions)\n",
    "print(f'criterion = entropy : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que con el algoritmo anterior probamos con el valor de \"entropy\" para \"criterion\", en este caso se obtiene un mejor resultado con el valor por defecto \"gini\", por lo que mantendremos este último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 2 : 0.7900466562986003\n",
      "min_samples_split = 3 : 0.7807153965785381\n",
      "min_samples_split = 4 : 0.7838258164852255\n",
      "min_samples_split = 5 : 0.7853810264385692\n",
      "min_samples_split = 6 : 0.7869362363919129\n",
      "min_samples_split = 7 : 0.7900466562986003\n"
     ]
    }
   ],
   "source": [
    "for split in range(2,8):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=40, min_samples_split=split)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'min_samples_split = {split} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al probar con diversos valores para \"min_samples_split\", en este caso tenemos los mejores resultados con el valor por defecto y con el valor de 7, por lo que dejaremos el primero por mayor simplicidad en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1 : 0.7573872472783826\n",
      "min_samples_split = 2 : 0.7807153965785381\n",
      "min_samples_split = 3 : 0.7838258164852255\n",
      "min_samples_split = 4 : 0.7869362363919129\n",
      "min_samples_split = 5 : 0.7916018662519441\n",
      "min_samples_split = 6 : 0.7947122861586314\n",
      "min_samples_split = 7 : 0.7900466562986003\n",
      "min_samples_split = 8 : 0.7947122861586314\n",
      "min_samples_split = 9 : 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,10):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=40, max_depth=depth)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'min_samples_split = {depth} : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se probó modificando el valor de \"max_depth\", obteniendo los mejores resultados con los valores de 6 y 8, escogiendo el valor de 6 para reducir los tiempos de cálculo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las pruebas realizados con el algoritmo de \"bosque aleatorio\", finalmente nos quedamos con un valor de \"n_estimators\" de 40, un valor de \"max_depth\" de 8 y el resto de los hiperparámetros por defecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = liblinear : 0.6967340590979783\n",
      "solver = newton-cg : 0.7589424572317263\n",
      "solver = lbfgs : 0.7589424572317263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\digom\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\digom\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\digom\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Users\\digom\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\digom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "for solv in ['liblinear','newton-cg','lbfgs']:\n",
    "    model = LogisticRegression(random_state=12345, solver=solv)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid) \n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "    print(f'solver = {solv} : {result}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como último algoritmo de aprendizaje estudiamos la \"regresión logística\", en este caso probamos distintos valores para \"solver\" concluyendo que los mejores resultados se obtienen con los valores de \"newton-cg\" y \"lbfgs\", elegiremos este último por ser el valor por defecto del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calidad y elección del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente procederemos a evaluar los tres algoritmos con los hiperparámetros previamente escogidos y haciendo uso de nuestro conjunto de prueba para elegir el que tenga la mayor exactitud posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy : 0.7667185069984448\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy', random_state=12345, max_depth=5, min_samples_leaf=3)\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_test) \n",
    "result = accuracy_score(target_test, predictions)\n",
    "print(f'Decision Tree accuracy : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy : 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=40, max_depth=6)\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_test) \n",
    "result = accuracy_score(target_test, predictions)\n",
    "print(f'Random Forest accuracy : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy : 0.7262830482115086\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_test) \n",
    "result = accuracy_score(target_test, predictions)\n",
    "print(f'Logistic Regression accuracy : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando los resultados obtenidos con los distintos modelos, podemos descartar inmediatamente la regresión logística ya que no cumple el umbral de exactitud requerido de 0.75, entre los dos restantes el que mayor exactitud posee es el modelo creado con el algoritmo de aprendizaje de bosque aleatorio, llegando a un 0.78 de exactitud, por lo que será este el elegido para cumplir el fin del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Prueba de cordura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procederá a realizar una prueba de cordura al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6889580093312597"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_test = [0]*643\n",
    "result = accuracy_score(target_test,sanity_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar una prueba de cordura con un modelo que predijera que todos los planes son 0 (Smart), la exactitud del modelo es de un 68,8%. Debido a lo anterior, podemos afirmar que nuestro modelo es más exacto que un modelo aleatorio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusión general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el proyecto realizando una rápida exploración de la base de datos entregada por Megaline no encontrando ningún parámetro que hubiera que ser abordado, a su vez se pudieron identificar las columnas \"características\" y \"objetivo\" de nuestro modelo a realizar, además de que se dio constancia que la columna \"objetivo\" es de tipo categórica.\n",
    "\n",
    "Continuamos realizando una segmentación de los datos en base a la identificación de las columnas realizadas en la sección anterior. Debido a que se nos entregó una sola base de datos y no poseíamos un conjunto de datos separados para realizar las pruebas finales procedimos a segmentar esta base en tres conjuntos, de entrenamiento, validación y prueba, en una proporción de 3:1:1.\n",
    "\n",
    "Damos paso al entrenamiento de los modelos y mejoramiento de los mismos a través de probar distintos valores para sus hiperparámetros, con esto obtuvimos un set de valores definidos que nos otorgaban la mayor exactitud posible para cada modelo basado en un algoritmo de aprendizaje distinto.\n",
    "\n",
    "Finalmente procedimos a comparar los distintos modelos con el conjunto de datos de prueba para poder analizar cuál es el más exacto, los resultados finales nos entregaron que el modelo que entregaba valores más exactos en el que está basado en el bosque aleatorio por lo cual sería este modelo el que le entregaríamos a Megaline para que pueda recomendar sus nuevos planes a sus clientes."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 47,
    "start_time": "2022-08-01T13:18:23.844Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-01T13:18:30.371Z"
   },
   {
    "duration": 399,
    "start_time": "2022-08-01T13:18:33.998Z"
   },
   {
    "duration": 51,
    "start_time": "2022-08-01T13:18:36.284Z"
   },
   {
    "duration": 123,
    "start_time": "2022-08-01T13:18:56.914Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-01T13:22:56.365Z"
   },
   {
    "duration": 2,
    "start_time": "2022-08-01T13:29:04.981Z"
   },
   {
    "duration": 654,
    "start_time": "2022-08-01T13:29:09.327Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-01T13:31:51.594Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T13:31:55.561Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-01T13:50:54.597Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-01T14:29:45.985Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-01T14:30:46.247Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-01T14:30:56.470Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-01T14:31:10.717Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-01T14:31:20.064Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T14:31:28.027Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-01T14:32:47.250Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-01T14:32:48.519Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T14:32:49.456Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-01T14:32:50.408Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T14:32:51.328Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-01T14:54:23.524Z"
   },
   {
    "duration": 46,
    "start_time": "2022-08-01T14:55:46.880Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-01T14:56:06.553Z"
   },
   {
    "duration": 56,
    "start_time": "2022-08-01T14:56:09.930Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-01T15:10:27.836Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-01T15:10:38.140Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-01T15:10:41.232Z"
   },
   {
    "duration": 55,
    "start_time": "2022-08-01T15:11:18.137Z"
   },
   {
    "duration": 57,
    "start_time": "2022-08-01T15:12:03.066Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T15:13:27.266Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T15:26:12.298Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-01T15:27:05.520Z"
   },
   {
    "duration": 270,
    "start_time": "2022-08-01T15:27:32.962Z"
   },
   {
    "duration": 272,
    "start_time": "2022-08-01T15:28:06.076Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-01T16:26:01.515Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-01T16:27:34.196Z"
   },
   {
    "duration": 238,
    "start_time": "2022-08-01T16:27:46.277Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T16:27:48.846Z"
   },
   {
    "duration": 70,
    "start_time": "2022-08-01T19:44:10.105Z"
   },
   {
    "duration": 1170,
    "start_time": "2022-08-01T19:44:19.503Z"
   },
   {
    "duration": 118,
    "start_time": "2022-08-01T19:44:22.931Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-01T19:44:27.015Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-01T19:44:28.509Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-01T19:44:28.973Z"
   },
   {
    "duration": 72,
    "start_time": "2022-08-01T19:44:31.214Z"
   },
   {
    "duration": 66,
    "start_time": "2022-08-01T19:54:28.364Z"
   },
   {
    "duration": 67,
    "start_time": "2022-08-01T19:54:38.987Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T19:59:02.932Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T19:59:20.052Z"
   },
   {
    "duration": 67,
    "start_time": "2022-08-01T19:59:38.682Z"
   },
   {
    "duration": 17,
    "start_time": "2022-08-01T20:00:04.642Z"
   },
   {
    "duration": 54,
    "start_time": "2022-08-01T20:01:36.063Z"
   },
   {
    "duration": 16,
    "start_time": "2022-08-01T20:01:40.231Z"
   },
   {
    "duration": 70,
    "start_time": "2022-08-01T20:01:53.626Z"
   },
   {
    "duration": 66,
    "start_time": "2022-08-01T20:02:10.336Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-01T20:02:21.264Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-01T20:02:25.087Z"
   },
   {
    "duration": 45,
    "start_time": "2022-08-01T20:02:53.176Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-01T20:02:58.918Z"
   },
   {
    "duration": 309,
    "start_time": "2022-08-01T20:20:56.227Z"
   },
   {
    "duration": 274,
    "start_time": "2022-08-01T20:21:19.911Z"
   },
   {
    "duration": 395,
    "start_time": "2022-08-01T20:21:39.555Z"
   },
   {
    "duration": 381,
    "start_time": "2022-08-01T20:22:15.163Z"
   },
   {
    "duration": 80,
    "start_time": "2022-08-01T20:23:17.053Z"
   },
   {
    "duration": 66,
    "start_time": "2022-08-01T20:23:31.417Z"
   },
   {
    "duration": 248,
    "start_time": "2022-08-01T20:24:27.850Z"
   },
   {
    "duration": 247,
    "start_time": "2022-08-01T20:24:32.520Z"
   },
   {
    "duration": 246,
    "start_time": "2022-08-01T20:24:39.969Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T20:48:10.701Z"
   },
   {
    "duration": 108,
    "start_time": "2022-08-01T20:48:42.533Z"
   },
   {
    "duration": 39,
    "start_time": "2022-08-01T20:48:56.158Z"
   },
   {
    "duration": 26,
    "start_time": "2022-08-01T20:49:16.614Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-01T20:49:23.129Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-01T20:57:48.718Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T20:58:41.264Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-01T21:13:06.499Z"
   },
   {
    "duration": 61,
    "start_time": "2022-08-01T21:14:03.804Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-01T23:46:26.922Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-01T23:46:32.070Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-01T23:47:29.135Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-01T23:47:37.583Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-01T23:48:15.345Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-01T23:49:13.072Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-02T00:15:45.420Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-02T00:16:07.484Z"
   },
   {
    "duration": 43,
    "start_time": "2022-08-02T00:39:33.214Z"
   },
   {
    "duration": 45,
    "start_time": "2022-08-02T00:55:53.656Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T00:56:25.910Z"
   },
   {
    "duration": 248,
    "start_time": "2022-08-02T01:19:40.792Z"
   },
   {
    "duration": 53,
    "start_time": "2022-08-02T01:20:03.199Z"
   },
   {
    "duration": 253,
    "start_time": "2022-08-02T01:20:26.094Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T01:28:11.225Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T01:28:25.732Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-02T01:28:39.824Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-02T01:28:50.375Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-02T01:28:54.783Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-02T01:29:13.558Z"
   },
   {
    "duration": 1087,
    "start_time": "2022-08-02T01:52:58.800Z"
   },
   {
    "duration": 29,
    "start_time": "2022-08-02T01:52:59.889Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-02T01:52:59.920Z"
   },
   {
    "duration": 18,
    "start_time": "2022-08-02T01:52:59.935Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-02T01:52:59.956Z"
   },
   {
    "duration": 4,
    "start_time": "2022-08-02T01:52:59.966Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-02T01:52:59.971Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-02T01:52:59.977Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-02T01:52:59.985Z"
   },
   {
    "duration": 34,
    "start_time": "2022-08-02T01:52:59.992Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-02T01:53:00.028Z"
   },
   {
    "duration": 66,
    "start_time": "2022-08-02T01:53:00.077Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T01:53:00.145Z"
   },
   {
    "duration": 69,
    "start_time": "2022-08-02T01:53:00.160Z"
   },
   {
    "duration": 272,
    "start_time": "2022-08-02T01:53:00.230Z"
   },
   {
    "duration": 62,
    "start_time": "2022-08-02T01:53:00.504Z"
   },
   {
    "duration": 261,
    "start_time": "2022-08-02T01:53:00.568Z"
   },
   {
    "duration": 11,
    "start_time": "2022-08-02T01:53:00.830Z"
   },
   {
    "duration": 116,
    "start_time": "2022-08-02T01:53:00.843Z"
   },
   {
    "duration": 36,
    "start_time": "2022-08-02T01:53:00.961Z"
   },
   {
    "duration": 28,
    "start_time": "2022-08-02T01:53:00.999Z"
   },
   {
    "duration": 47,
    "start_time": "2022-08-02T01:53:01.029Z"
   },
   {
    "duration": 58,
    "start_time": "2022-08-02T01:53:01.078Z"
   },
   {
    "duration": 3,
    "start_time": "2022-08-02T01:53:47.965Z"
   },
   {
    "duration": 1335,
    "start_time": "2022-08-02T19:59:30.853Z"
   },
   {
    "duration": 67,
    "start_time": "2022-08-02T19:59:32.191Z"
   },
   {
    "duration": 15,
    "start_time": "2022-08-02T19:59:32.260Z"
   },
   {
    "duration": 25,
    "start_time": "2022-08-02T19:59:32.278Z"
   },
   {
    "duration": 10,
    "start_time": "2022-08-02T19:59:32.306Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-02T19:59:32.318Z"
   },
   {
    "duration": 6,
    "start_time": "2022-08-02T19:59:32.324Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-02T19:59:32.332Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-02T19:59:32.343Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T19:59:32.355Z"
   },
   {
    "duration": 94,
    "start_time": "2022-08-02T19:59:32.370Z"
   },
   {
    "duration": 67,
    "start_time": "2022-08-02T19:59:32.466Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-02T19:59:32.535Z"
   },
   {
    "duration": 82,
    "start_time": "2022-08-02T19:59:32.550Z"
   },
   {
    "duration": 331,
    "start_time": "2022-08-02T19:59:32.634Z"
   },
   {
    "duration": 70,
    "start_time": "2022-08-02T19:59:32.967Z"
   },
   {
    "duration": 316,
    "start_time": "2022-08-02T19:59:33.038Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-02T19:59:33.356Z"
   },
   {
    "duration": 135,
    "start_time": "2022-08-02T19:59:33.371Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-02T19:59:33.507Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-02T19:59:33.550Z"
   },
   {
    "duration": 81,
    "start_time": "2022-08-02T19:59:33.564Z"
   },
   {
    "duration": 44,
    "start_time": "2022-08-02T19:59:33.647Z"
   },
   {
    "duration": 2018,
    "start_time": "2022-08-02T22:35:02.541Z"
   },
   {
    "duration": 31,
    "start_time": "2022-08-02T22:35:04.561Z"
   },
   {
    "duration": 14,
    "start_time": "2022-08-02T22:35:04.594Z"
   },
   {
    "duration": 19,
    "start_time": "2022-08-02T22:35:04.611Z"
   },
   {
    "duration": 9,
    "start_time": "2022-08-02T22:35:04.632Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-02T22:35:04.642Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-02T22:35:04.652Z"
   },
   {
    "duration": 8,
    "start_time": "2022-08-02T22:35:04.660Z"
   },
   {
    "duration": 5,
    "start_time": "2022-08-02T22:35:04.670Z"
   },
   {
    "duration": 7,
    "start_time": "2022-08-02T22:35:04.678Z"
   },
   {
    "duration": 52,
    "start_time": "2022-08-02T22:35:04.711Z"
   },
   {
    "duration": 62,
    "start_time": "2022-08-02T22:35:04.765Z"
   },
   {
    "duration": 13,
    "start_time": "2022-08-02T22:35:04.828Z"
   },
   {
    "duration": 68,
    "start_time": "2022-08-02T22:35:04.843Z"
   },
   {
    "duration": 329,
    "start_time": "2022-08-02T22:35:04.913Z"
   },
   {
    "duration": 76,
    "start_time": "2022-08-02T22:35:05.244Z"
   },
   {
    "duration": 307,
    "start_time": "2022-08-02T22:35:05.322Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T22:35:05.631Z"
   },
   {
    "duration": 137,
    "start_time": "2022-08-02T22:35:05.644Z"
   },
   {
    "duration": 50,
    "start_time": "2022-08-02T22:35:05.783Z"
   },
   {
    "duration": 12,
    "start_time": "2022-08-02T22:35:05.835Z"
   },
   {
    "duration": 70,
    "start_time": "2022-08-02T22:35:05.849Z"
   },
   {
    "duration": 42,
    "start_time": "2022-08-02T22:35:05.921Z"
   },
   {
    "duration": 1084,
    "start_time": "2022-08-09T19:54:27.198Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
